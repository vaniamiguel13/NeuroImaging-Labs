{"cells":[{"cell_type":"markdown","metadata":{"id":"fYeayw0Cqny9"},"source":["# **Neuroimaging 2025/2026**\n","\n","**Lab Structural MRI**\n","\n","Tutors: Beatriz Vale & Vânia Miguel\n","\n","Created by: Marta Xavier & Neil Mehta\n"]},{"cell_type":"markdown","metadata":{"id":"mCaB4JKCchqj"},"source":["## **Objectives**\n","```\n","Implement main workflow to process structural Magnetic Resonance Imaging (MRI) images:\n","\n","* Setting up MRI analysis packages;\n","* Perform brain extraction using different analysis packages (ANTS, AFNI, FreeSurfer, FSL);\n","* Perform image segmentation into the main brain tissue classes;\n","* Perform image registration, by applying linear and nonlinear transformations.  \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"u9GJoLonpj0-"},"source":["# **I. Set up the environment**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xOcwCMfjamH"},"outputs":[],"source":["# Set up Neurodesk\n","%%capture\n","import os\n","import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","if IN_COLAB:\n","    os.environ[\"LD_PRELOAD\"] = \"\";\n","    os.environ[\"APPTAINER_BINDPATH\"] = \"/content\"\n","    os.environ[\"MPLCONFIGDIR\"] = \"/content/matplotlib-mpldir\"\n","    os.environ[\"LMOD_CMD\"] = \"/usr/share/lmod/lmod/libexec/lmod\"\n","\n","    !curl -J -O https://raw.githubusercontent.com/neurodesk/neurocommand/main/googlecolab_setup.sh\n","    !chmod +x googlecolab_setup.sh\n","    !./googlecolab_setup.sh\n","\n","    os.environ[\"MODULEPATH\"] = ':'.join(map(str, list(map(lambda x: os.path.join(os.path.abspath('/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/'), x),os.listdir('/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/')))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0EphhWVNz0bY"},"outputs":[],"source":["\n","# Download analysis packages\n","import lmod\n","\n","# Set up AFNI\n","await lmod.load('afni/24.1.02')\n","\n","# Set up FreeSurfer\n","await lmod.load('freesurfer/7.3.2')\n","\n","# Set up FSL\n","await lmod.load('fsl/6.0.7.4')"]},{"cell_type":"markdown","metadata":{"id":"GALFSZKUw7Zp"},"source":["# **II. Download example data**\n","\n","Example data from FMRIB Software Library (FSL): [(link)](https://open.win.ox.ac.uk/pages/fslcourse/website/downloads.html)"]},{"cell_type":"markdown","metadata":{"id":"BJoMAa84DVmm"},"source":["## 1. Download dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jhGXfm9COhGF"},"outputs":[],"source":["# Download T1-weighted (T1w) and T2-weighted (T2w) MRI structural data from FSL\n","!wget https://www.fmrib.ox.ac.uk/primers/intro_primer/ExBox17/ExBox17.zip\n","!unzip ExBox17.zip\n","!rm ExBox17.zip\n","\n","# Permissions\n","!chmod -R 777 *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqT55U9PAMl-"},"outputs":[],"source":["# Change working directory\n","path = \"ExBox17\"\n","os.chdir(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsAFhg01blWk"},"outputs":[],"source":["# Copy standard structural images from MNI to current directory\n","!cp $FSLDIR/data/standard/MNI152_T1_2mm.nii.gz standard.nii.gz\n","!cp $FSLDIR/data/standard/MNI152_T1_2mm_brain.nii.gz standard_brain.nii.gz\n","!cp $FSLDIR/etc/flirtsch/T1_2_MNI152_2mm.cnf ."]},{"cell_type":"markdown","metadata":{"id":"hZrHkG7DBQ00"},"source":["## 2. Dataset contents\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RUPeRVjlCAGk"},"source":["You can check the contents of the `ExBox17` folder in the files tab of this notebook, or by listing the contents of the working directory, using the SHELL command `!ls`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9vCxf-GCLxO"},"outputs":[],"source":["# List the contents of the current directory\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"qHc0334NBrhk"},"source":["```\n","Contents:\n","* T1-weighted (T1-w) structural scan: T1\n","* T1-w structural scan, skull-stripped: T1_brain\n","* T2-weighted (T2-w) structural scan: T2\n","* T2-w structural scan, skull-stripped: T2_brain\n","* Standard MNI template of structural scan: standard\n","* Standard MNI template of structural scan, skull-stripped: standard_brain\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"lx87NRnKbTVa"},"source":["### Check dataset images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyANrpA4bsUV"},"outputs":[],"source":["# Import visualization packages\n","from ipyniivue import AnyNiivue\n","from IPython.display import display, Markdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACDa1UjCbiWn"},"outputs":[],"source":["# Check T1w image info\n","!fslinfo T1"]},{"cell_type":"markdown","metadata":{"id":"RszCaoxHcHLd"},"source":["**Relevant informations:**\n","\n","- Number of voxels: `dim1`, `dim2`, `dim3`.\n","- Voxel size: `pixdim1`, `pixdim2`, `pixdim3`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uekMRGyb21T"},"outputs":[],"source":["# Visualize T1w image\n","display(Markdown(\"### T1w structural image\"))\n","\n","nv_T1 = AnyNiivue()\n","nv_T1.load_volumes([{\"path\": \"T1.nii.gz\"}])\n","nv_T1"]},{"cell_type":"markdown","metadata":{"id":"5ZWCVJmicsli"},"source":["**Images, from left to right:**\n","\n","- Axial slices: A (anterior) on top; P (posterior) on the bottom; L (left) on the left, R (right) on the right.\n","- Coronal slices: S (superior) on top, I (inferior) on the bottom; L (left) on the left, R (right) on the right.\n","- Sagittal slices: S (superior) on top, I (inferior) on the bottom; P (posterior) on the left, A (anterior) on the right.\n","- 3D rendition of the brain."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3n8_cX-wg23i"},"outputs":[],"source":["# Check T2w image info\n","!fslinfo T2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXGW-uoZg6Mu"},"outputs":[],"source":["# Visualize T2w image\n","display(Markdown(\"### T2w structural image\"))\n","\n","nv_T1 = AnyNiivue()\n","nv_T1.load_volumes([{\"path\": \"T2.nii.gz\"}])\n","nv_T1"]},{"cell_type":"markdown","metadata":{"id":"WFetgfL7h9N1"},"source":["T1 and T2 are, respectively, the longitudinal and transverse relaxation time. Different tissues have different T1 and T2 values:\n","  - T1 (WM) > T1 (GM): white matter is brighter in T1w images.\n","  - T2 (WM) < T2 (GM): grey matter is brighter in T2w images."]},{"cell_type":"markdown","metadata":{"id":"kYVN4AW4piWk"},"source":["# **III. Brain extraction**\n","\n","Adapted from [(link)](https://www.neurodesk.org/example-notebooks/structural_imaging/brain_extraction_different_tools.html#)"]},{"cell_type":"markdown","metadata":{"id":"8ah2mm7fgJGM"},"source":["MRI studies focus on brain tissue, so typically the first processing step is to remove the skull and non-brain areas from the image.\n","\n","This is usually called _brain extraction_ or _skull-stripping_.\n","\n","In this example we will use the following MRI analysis packages and algorithms to skull-strip the anatomical image:\n","\n","*   Analysis of Functional NeuroImages (AFNI): 3dSkullStrip [(link)](https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dSkullStrip.html)\n","*   FreeSurfer: SynthStrip [(link)](https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/)\n","*   FSL (FMRIB Software Library): BET  [(link)](https://open.win.ox.ac.uk/pages/fslcourse/practicals/intro2/index.html)"]},{"cell_type":"markdown","metadata":{"id":"32wDi47H4L_c"},"source":["## 1. AFNI: 3dSkullStrip"]},{"cell_type":"markdown","metadata":{"id":"_w43j2YQl3e1"},"source":["AFNI is a suite of programs designed to analyze fMRI data.\n","3dSkullStrip can be used for brain extraction. [(link)](https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dSkullStrip.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ocYqtaJW5eu0"},"outputs":[],"source":["# Usage\n","!3dSkullStrip -help"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ruGekXDm5gyS"},"outputs":[],"source":["# Run\n","!3dSkullStrip -input T1.nii.gz -prefix T1_brain_AFNI.nii.gz -push_to_edge"]},{"cell_type":"markdown","metadata":{"id":"LFFtFRLp4VMp"},"source":["## 2. Freesurfer:  SynthStrip"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"040PeE4W5qwU"},"outputs":[],"source":["# Usage\n","!mri_synthstrip --help"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"qsCo4vTh5tuD"},"outputs":[],"source":["# Run\n","!mri_synthstrip -i T1.nii.gz -o T1_brain_freesurfer.nii.gz -m synth_mask.nii.gz"]},{"cell_type":"markdown","metadata":{"id":"Sxj6Lg2YmFg3"},"source":["FreeSurfer is a software package that enables you to analyze structural MRI images. You can use FreeSurfer to quantify the amount of grey matter and white matter in specific regions of the brain. You will also be able to calculate measurements such as the thickness, curvature, and volume of the different tissue types, and be able to correlate these with covariates; or, you can contrast these structural measurements between groups.\n","\n","FreeSurfer’s SynthStrip is a skull-stripping tool that extracts brain voxels from a landscape of image types, ranging across imaging modalities, resolutions, and subject populations. It leverages a deep learning strategy to synthesize arbitrary training images from segmentation maps, yielding a robust model agnostic to acquisition specifics. [(link)](https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/)"]},{"cell_type":"markdown","metadata":{"id":"3ijfHmgTxsoS"},"source":["## 5. FSL: BET"]},{"cell_type":"markdown","metadata":{"id":"OEPCNr22mMkq"},"source":["FSL is a library of analysis tools for fMRI, MRI and diffusion brain imaging data.\n","\n","FSL has a tool to skull-strip an anatomical image called BET (Brain Extraction Tool). [(link)](https://open.win.ox.ac.uk/pages/fslcourse/practicals/intro2/index.html), [(link)](https://fsl.fmrib.ox.ac.uk/fsl/docs/#/structural/bet)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"rE-k6XSK0PTU"},"outputs":[],"source":["# Usage\n","!bet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3reLHrc0TxI"},"outputs":[],"source":["# Run BET\n","!bet T1 T1_brain -f 0.5 # define intensity threshold = 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hywp36z70gLl"},"outputs":[],"source":["# Run BET with varying intensity threshold\n","!bet T1 T1_brain_f02 -f 0.2 # define intensity threshold = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fJvXEscS1XaZ"},"outputs":[],"source":["# Run BET and create a binary brain mask\n","!bet T1 T1_brain.nii.gz -f 0.5 -m"]},{"cell_type":"markdown","metadata":{"id":"wD-8lWwO6Ar_"},"source":["## 6. Visualize Results"]},{"cell_type":"markdown","metadata":{"id":"vp6oTUo4nWCT"},"source":["We can compare the original T1w MRI image with the skull-stripped results from the different analysis softwares used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KzDvcMtidg6R"},"outputs":[],"source":["# Visualize original T1 image (before brain extraction)\n","display(Markdown(\"### T1w structural image\"))\n","\n","nv_T1 = AnyNiivue()\n","nv_T1.load_volumes([{\"path\": \"T1.nii.gz\"}])\n","nv_T1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bp-pNdd46f78"},"outputs":[],"source":["# Visualize AFNI results\n","display(Markdown(\"### AFNI 3dSkullStrip\"))\n","\n","nv_AFNI = AnyNiivue()\n","nv_AFNI.load_volumes([{\"path\": \"T1_brain_AFNI.nii.gz\"}])\n","nv_AFNI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7_UAdkj6g6z"},"outputs":[],"source":["# Visualize FreeSurfer results\n","display(Markdown(\"### FreeSurfer SynthStrip\"))\n","\n","nv_FreeSurfer = AnyNiivue()\n","nv_FreeSurfer.load_volumes([{\"path\": \"T1_brain_freesurfer.nii.gz\"}])\n","nv_FreeSurfer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fe6Ioh6g6kxk"},"outputs":[],"source":["# Visualize FSL's BET results\n","# Threshold = 0.5 (default)\n","display(Markdown(\"### FSL BET (Thr=0.5)\"))\n","\n","nv_FSL = AnyNiivue()\n","nv_FSL.load_volumes([{\"path\": \"T1_brain.nii.gz\"}])\n","nv_FSL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MThRg3dz7XZi"},"outputs":[],"source":["# Visualize FSL's BET results\n","# Threshold = 0.2\n","display(Markdown(\"### FSL BET (Thr=0.2)\"))\n","\n","nv_FSL = AnyNiivue()\n","nv_FSL.load_volumes([{\"path\": \"T1_brain_f02.nii.gz\"}])\n","nv_FSL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3hjjlVDSneX"},"outputs":[],"source":["# Visualize FSL's BET results\n","# Binary brain mask\n","display(Markdown(\"### FSL BET (Thr=0.5), Brain Mask\"))\n","\n","nv_FSL = AnyNiivue()\n","nv_FSL.load_volumes([{\"path\": \"T1_brain_mask.nii.gz\"}])\n","nv_FSL"]},{"cell_type":"markdown","metadata":{"id":"dJNGj7wD7qx5"},"source":["# **IV. Tissue segmentation**\n","\n","Adapted from [(link)](https://open.win.ox.ac.uk/pages/fslcourse/practicals/seg_struc/index.html)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qDaFIPZPiWAd"},"source":["We can use FSL's tools FIRST and FAST to perform tissue segmentation."]},{"cell_type":"markdown","metadata":{"id":"y9q_FblN9IAB"},"source":["## 1. FAST: tissue type segmentation and bias-field correction"]},{"cell_type":"markdown","metadata":{"id":"17V8b2SUn2XX"},"source":["FSL's tool FAST can be used to perform bias field correction, as well as tissue type segmentation, on the skull stripped T1w structural image. [(link)](https://fsl.fmrib.ox.ac.uk/fsl/docs/#/structural/fast)\n","\n","_Tissue type segmentation_: segment the structural image into grey matter, white matter and  CSF.\n","\n","_Bias-field correction_: correct the artifacts resultant of uneven intisities due to RF or B1 inhomogeneities.\n"]},{"cell_type":"markdown","metadata":{"id":"4U96cfE9IhBn"},"source":["### **Run FAST**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"uSsCalG0YslB"},"outputs":[],"source":["# Usage\n","!fast"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"86wULPPb9CSW"},"outputs":[],"source":["# Run fast (with bias field correction)\n","!fast -b -B T1_brain"]},{"cell_type":"markdown","metadata":{"id":"3n80PJlZJMFq"},"source":["### **Check Outputs**"]},{"cell_type":"markdown","metadata":{"id":"LsI-GQgRI70J"},"source":["*  Bias field corrected image: `T1_brain_restore`\n","*  Bias field: `T1_brain_bias`\n","*  CSF image: `T1_brain_pve_0`\n","*  Grey matter image: `T1_brain_pve_1`\n","*  White matter image: `T1_brain_pve_2`"]},{"cell_type":"markdown","metadata":{"id":"VR_InUT9J0_9"},"source":["### **Visualize Results**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_BqPSlwjXEp"},"outputs":[],"source":["# Visualize FSL's FAST results\n","# Bias field\n","display(Markdown(\"### FSL FAST - Bias field\"))\n","\n","nv_FAST_bias = AnyNiivue()\n","nv_FAST_bias.load_volumes([{\"path\": \"T1_brain_bias.nii.gz\"}])\n","nv_FAST_bias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxBEY-1BjeG9"},"outputs":[],"source":["# Visualize FSL's FAST results\n","# Bias field corrected T1w structural image\n","display(Markdown(\"### FSL FAST - Bias field corrected T1w image\"))\n","\n","nv_FAST_restore = AnyNiivue()\n","nv_FAST_restore.load_volumes([{\"path\": \"T1_brain_restore.nii.gz\"}])\n","nv_FAST_restore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzOQZAnkYlS_"},"outputs":[],"source":["# Visualize FSL's FAST results\n","# CSF\n","display(Markdown(\"### FSL FAST - CSF\"))\n","\n","nv_FAST_CSF = AnyNiivue()\n","nv_FAST_CSF.load_volumes([{\"path\": \"T1_brain_pve_0.nii.gz\"}])\n","nv_FAST_CSF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xi8P-si8ifB-"},"outputs":[],"source":["# Visualize FSL's FAST results\n","# Grey matter\n","display(Markdown(\"### FSL FAST - Grey matter\"))\n","\n","nv_FAST_GM = AnyNiivue()\n","nv_FAST_GM.load_volumes([{\"path\": \"T1_brain_pve_1.nii.gz\"}])\n","nv_FAST_GM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_VwvylljC1A"},"outputs":[],"source":["# Visualize FSL's FAST results\n","# White Matter\n","display(Markdown(\"### FSL FAST - White matter\"))\n","\n","nv_FAST_WM = AnyNiivue()\n","nv_FAST_WM.load_volumes([{\"path\": \"T1_brain_pve_2.nii.gz\"}])\n","nv_FAST_WM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gfl8Fjhus29Q"},"outputs":[],"source":["# Visualize FSL's FAST results\n","# CSF, grey matter, white matter (overlayed)\n","display(Markdown(\"### FSL FAST - CSF (red), GM (blue), WM (white)\"))\n","\n","nv_FAST_all = AnyNiivue()\n","volumes = [{\"path\": \"T1_brain_pve_2.nii.gz\", \"colormap\": \"white\"},\n","           {\"path\": \"T1_brain_pve_0.nii.gz\", \"colormap\": \"red\"},\n","           {\"path\": \"T1_brain_pve_1.nii.gz\", \"colormap\": \"blue\"}]\n","nv_FAST_all.load_volumes(volumes)\n","nv_FAST_all"]},{"cell_type":"markdown","metadata":{"id":"XBZ8az-4_ZNd"},"source":["## 2. FIRST: segmentation of sub-cortical structures\n"]},{"cell_type":"markdown","metadata":{"id":"X5EonWH4p90G"},"source":["\n","FSL's tool FIRST can be used to perform segmentation of the skull stripped T1w structural image into several sub-cortical structures. [(link)](https://fsl.fmrib.ox.ac.uk/fsl/docs/#/structural/first?id=segmentation-with-run_first_all)\n"]},{"cell_type":"markdown","metadata":{"id":"s7uukcuGKMYV"},"source":["### **Run FIRST**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"SyGouL6xTYpG"},"outputs":[],"source":["# Usage\n","!run_first_all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERCpG5fS_wAu"},"outputs":[],"source":["# Perform segmentation of sub-cortical structures\n","!run_first_all -i T1_brain -b -o T1_brain_segmented"]},{"cell_type":"markdown","metadata":{"id":"_OHO6B9oKPcJ"},"source":["### **Check Outputs**"]},{"cell_type":"markdown","metadata":{"id":"X1BPd9NFKa_0"},"source":["* `T1_all_fast_firstseg`: This is a single image showing the segmented output for all structures. The image is produced by filling the estimated surface meshes and then running a step to ensure that there is no overlap between structures. The output uses the labels listed above (and a standard colour table is built into FSleyes). If another boundary correction method is specified, the name fast in this filename will change to reflect the boundary correction that is used. Note that if only one structure is specified then this file will be called T1-struct_corr.nii.gz instead (e.g. sub001-L_Caud_corr.nii.gz).\n","\n","* `T1_all_fast_origsegs`: This is a 4D image containing the individual structure segmentations, converted directly from the native mesh representation and without any boundary correction. For each structure there is an individual 3D image where the interior is labeled according to the CMA standard labels while the boundary uses these label values plus 100. Note that if only one structure is specified then this file will be called T1-struct_first.nii.gz instead (e.g. sub001-L_Caud_first.nii.gz).\n","\n","Example labels:\n","```\n","10 Left Thalamus (L_Thal); 11 Left Caudate (L_Caud); 12 Left Putamen (L_Puta); 13 Left Pallidum (L_Pall); 16 Brain Stem (BrStem); 17 Left Hippocampus (L_Hipp); 18 Left Amygdala (L_Amyg); 26 Left Accumbens (L_Accu); 49 Right Thalamus (R_Thal); 50 Right Caudate (R_Caud); 51 Right Putamen (R_Puta); 52 Right Pallidum (R_Pall); 53 Right Hippocampus (R_Hipp); 54 Right Amygdala (R_Amyg); 58 Right Accumbens (R_Accu)\n","```"]},{"cell_type":"markdown","metadata":{"id":"yLUbssfoKRWo"},"source":["### **Visualize Results**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_diuulMzLhm"},"outputs":[],"source":["# Visualize FSL results\n","# FIRST\n","display(Markdown(\"### FSL FIRST - Segmentation\"))\n","\n","nv_FSL = AnyNiivue()\n","nv_FSL.load_volumes([{\"path\": \"T1_brain_segmented_all_fast_firstseg.nii.gz\"}])\n","nv_FSL\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnhWwvms-u_d"},"outputs":[],"source":["!fslstats T1_brain_segmented_all_fast_firstseg -R"]},{"cell_type":"markdown","metadata":{"id":"TQKgkpAMAOZh"},"source":["# **V. Registration**\n","\n","Adapted from [(link)](https://www.fmrib.ox.ac.uk/primers/intro_primer/ExBox17/IntroBox17.html)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"esdB1LKriv__"},"source":["We can use FSL's tools FLIRT and FNIRT to perform linear and non-linear registration of MRI images."]},{"cell_type":"markdown","metadata":{"id":"RnT4toLvA8wT"},"source":["## 1. FLIRT: within-subject registration\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PSYnCapuvU0t"},"source":["\n","We can use linear registration, using FSL's FLIRT, for within-subject registration. [(link)](https://web.mit.edu/fsl_v5.0.10/fsl/doc/wiki/FLIRT(2f)UserGuide.html)\n","\n","For example, to register a subject's T2-weighted image to the T1-weighted image, or to register a subject's functional image to the T1-weighted image."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"YBdD_Idly8rm"},"outputs":[],"source":["# Usage\n","!flirt"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"yCsQcT9R1yjS"},"outputs":[],"source":["# Perform brain extraction/skull stripping on T2w structural image\n","!bet T2 T2_brain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AmeQ59XL2cAp"},"outputs":[],"source":["# Visualize results (before registration)\n","display(Markdown(\"### T2w (blue) and T1w (red) - before registration\"))\n","\n","nv_FSL = AnyNiivue()\n","volumes =  [{\"path\": \"T2_brain.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"T1_brain.nii.gz\", \"colormap\": \"red\"}]\n","nv_FSL.load_volumes(volumes)\n","nv_FSL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoDRxLajBO6x"},"outputs":[],"source":["# Use a linear transformation with 6 DOF to register the subject's T2w to T1w structural images\n","# Cost function: least squares\n","!flirt -in T2_brain.nii.gz -ref T1_brain.nii.gz -dof 6 -cost leastsq -omat T2toT1_LS.mat -out T2toT1_LS\n","\n","# Cost function: mutual information\n","!flirt -in T2_brain -ref T1_brain.nii.gz -dof 6 -cost mutualinfo -omat T2toT1_MI.mat -out T2toT1_MI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXEkDvPp3STi"},"outputs":[],"source":["# Visualize results (after registration, LS)\n","display(Markdown(\"### T2w (blue) and T1w (red) - after registration (LS)\"))\n","\n","nv_FLIRT_LS = AnyNiivue()\n","volumes =  [{\"path\": \"T2toT1_LS.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"T1_brain.nii.gz\", \"colormap\": \"red\"}]\n","nv_FLIRT_LS.load_volumes(volumes)\n","nv_FLIRT_LS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ur25GEOFvdSe"},"outputs":[],"source":["# Visualize results (after registration, MI)\n","display(Markdown(\"### T2w (blue) and T1w (red) - after registration (MI)\"))\n","\n","nv_FLIRT_MI = AnyNiivue()\n","volumes =  [{\"path\": \"T2toT1_MI.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"T1_brain.nii.gz\", \"colormap\": \"red\"}]\n","nv_FLIRT_MI.load_volumes(volumes)\n","nv_FLIRT_MI"]},{"cell_type":"markdown","metadata":{"id":"EPHRbiNHBccK"},"source":["## 2. FNIRT: between-subject registration"]},{"cell_type":"markdown","metadata":{"id":"QAegOJBAvlVu"},"source":["We can use non-linear registration, using FSL's FNIRT, for registration to standard space.\n","\n","In this case, we will register a subject’s T1-weighted image to the T1-weighted image in the MNI standard space (MNI152_T1)."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"sJmnMP2WRmxE"},"outputs":[],"source":["# Usage\n","!fnirt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rQMs5XdQSCB"},"outputs":[],"source":["# Visualize results (before registration)\n","display(Markdown(\"### Standard (blue) and T1w (red) - before registration\"))\n","\n","nv_FSL = AnyNiivue()\n","volumes =  [{\"path\": \"standard_brain.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"T1_brain.nii.gz\", \"colormap\": \"red\"}]\n","nv_FSL.load_volumes(volumes)\n","nv_FSL\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9uYNr7KBmBj"},"outputs":[],"source":["# It's common to use FLIRT to obtain an initial approximation of the transformation, which we can later input in FNIRT\n","# Use an affine linear transformation with 12 DOF\n","!flirt -in T1_brain.nii.gz -ref standard_brain -dof 12 -out T1toMNIlin -omat T1toMNIlin.mat\n","\n","# Provide the affine transformation matrix estimated in the step above to initialize the non-linear registration\n","!fnirt --in=T1_brain.nii.gz --aff=T1toMNIlin.mat --config=T1_2_MNI152_2mm.cnf --iout=T1toMNInonlin --cout=T1toMNI_coef --fout=T1toMNI_warp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9paxmt_QlOs"},"outputs":[],"source":["# Visualize results (after registration)\n","display(Markdown(\"### Standard MNI (blue) and T1w (red) - after registration\"))\n","\n","nv_FNIRT = AnyNiivue()\n","volumes =  [{\"path\": \"T1toMNInonlin.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"standard_brain.nii.gz\", \"colormap\": \"red\"}]\n","nv_FNIRT.load_volumes(volumes)\n","nv_FNIRT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTnYbBkeGENf"},"outputs":[],"source":["# Visualize results (after registration)\n","display(Markdown(\"### Standard MNI (blue) and T1w (red) - after linear registration\"))\n","\n","nv_FNIRT = AnyNiivue()\n","volumes =  [{\"path\": \"T1toMNIlin.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"standard_brain.nii.gz\", \"colormap\": \"red\"}]\n","nv_FNIRT.load_volumes(volumes)\n","nv_FNIRT"]},{"cell_type":"markdown","metadata":{"id":"3hL6kipKCLT6"},"source":["## 3. Combine transformations\n","\n","Now we will see how we can combine the two registrations performed in the two previous steps.\n","\n","In this case, this can be used to register the T2w structural image to the MNI standard space, using a single command."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXrST5CcCasb"},"outputs":[],"source":["# Apply sequentially the two transformations estimated above to register the T2w data into the standard MNI space\n","!applywarp -i T2_brain.nii.gz -r standard_brain --premat=T2toT1_MI.mat -w T1toMNI_warp.nii.gz -o T2toMNI.nii.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9-TDQWFRy6P"},"outputs":[],"source":["# Visualize results (after registration)\n","display(Markdown(\"### Standard MNI (blue) and T2w (red) - after registration\"))\n","\n","nv_WARP = AnyNiivue()\n","volumes =  [{\"path\": \"standard_brain.nii.gz\", \"colormap\": \"blue\"},\n","           {\"path\": \"T2toMNI.nii.gz\", \"colormap\": \"red\"}]\n","nv_WARP.load_volumes(volumes)\n","nv_WARP"]},{"cell_type":"markdown","source":["# **VI. Surface-based Analysis**\n","\n","Structural MRI studies typically acquire a **T1-weighted** anatomical image - a\n","high-resolution scan where white matter appears bright, gray matter appears darker, and CSF appears black. Traditional **volume-based analysis** of these images faces a fundamental problem: voxels at cortical folds contain mixed signals from multiple regions and tissue types (the **partial voluming effect**), making precise measurements difficult.\n","\n","[FreeSurfer](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurfer) solves this by reconstructing the cortex as a 2D surface mesh composed of vertices and edges. This surface can be inflated to reveal hidden sulci and allows direct measurement of cortical properties like thickness, curvature, and surface area - avoiding partial voluming effects and providing more anatomically accurate analysis ([link](https://andysbrainbook.readthedocs.io/en/latest/FreeSurfer/FS_ShortCourse/FS_01_BasicTerms.html)).\n","\n","\n"],"metadata":{"id":"CMxjPODQ-uAk"}},{"cell_type":"markdown","source":["## Surface Representations\n","\n","**FreeSurfer** creates several surface representations, each serving a different purpose:\n","\n","1. **White matter surface**: Inner boundary (gray/white matter interface)\n","2. **Pial surface**: Outer boundary (gray matter/CSF interface)  \n","3. **Inflated surface**: Smoothly inflated to reveal sulci (valleys) hidden in folds\n","4. **Sphere**: Maximally inflated for registration across subjects\n","\n","Let's visualize these different representations:"],"metadata":{"id":"arMEMOqe_wRs"}},{"cell_type":"code","source":["from nilearn import datasets, plotting\n","import matplotlib.pyplot as plt\n","\n","# Load the fsaverage template (average surface from ~40 subjects)\n","fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage')"],"metadata":{"id":"NJOBF4iM_v5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# White Matter Surface - Inner cortical boundary (gray/white interface)\n","# Red = gyri (outward), Green = sulci (inward)\n","\n","view = plotting.view_surf(\n","    fsaverage['white_left'],\n","    surf_map=fsaverage['sulc_left'],\n","    cmap='RdYlGn',\n","    symmetric_cmap=True,\n","    title='White Matter Surface',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"mhcMVwdHF5Lb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pial Surface - Description: Outer cortical boundary (gray/CSF interface)\n","# Red = gyri (outward), Green = sulci (inward)\n","\n","view = plotting.view_surf(\n","    fsaverage['pial_left'],\n","    surf_map=fsaverage['sulc_left'],\n","    cmap='RdYlGn',\n","    symmetric_cmap=True,\n","    title='Pial Surface',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"l8F-Qd-OGLGu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inflated Surface - \"Unfolds\" the brain, making it easier to see regions that are normally hidden deep in sulci.\n","\n","view = plotting.view_surf(\n","    fsaverage['infl_left'],\n","    surf_map=fsaverage['sulc_left'],\n","    cmap='RdYlGn',\n","    symmetric_cmap=True,\n","    title='Inflated Surface',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"KPpT-iFcGSsS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Surface-Based Morphometry (SBM)\n","\n","Surface-based morphometry involves measuring geometric properties of the cortical surface. Unlike volume-based morphometry (VBM) which looks at tissue density in 3D space, SBM measures properties intrinsic to the cortical sheet.\n","\n","1. **Sulcal Depth**: Distance from the outer cortical surface to a \"mid-cortical\" surface. Quantifies how deeply folded each region is.\n","2. **Curvature**: How much the surface bends at each point. Positive values = concave (sulci/valleys). Negative values = convex (gyri/ridges).\n","3. **Cortical Thickness**: Distance between white matter and pial surfaces. Typically 2-4mm, varies by region.\n","\n","Let's visualize these different metrics:"],"metadata":{"id":"Dv82vwuGBUiK"}},{"cell_type":"code","source":["# Sulcal Depth - Measures cortical folding depth.\n","# Red = gyri (outward), Green = sulci (inward)\n","\n","view = plotting.view_surf(\n","    fsaverage['pial_left'],\n","    surf_map=fsaverage['sulc_left'],\n","    cmap='RdYlGn',\n","    symmetric_cmap=True,\n","    title='Sulcal Depth',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"NKG5SWEUBwsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  Curvature - Surface bending\n","# Red = concave (sulci), Blue = convex (gyri)\n","\n","view = plotting.view_surf(\n","    fsaverage['pial_left'],\n","    surf_map=fsaverage['curv_left'],\n","    cmap='coolwarm',\n","    symmetric_cmap=True,\n","    title='Curvature',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"iP-M9BqZHNFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cortical Thickness\" - Distance between white and pial surfaces (mm).\n","# Warmer = thicker cortex\n","\n","view = plotting.view_surf(\n","    fsaverage['pial_left'],\n","    surf_map=fsaverage['thick_left'],\n","    cmap='hot',\n","    symmetric_cmap=False,\n","    title='Cortical Thickness',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"wQ9bdoK6HUqu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Projecting Functional Data onto Surfaces\n","\n","One of the key advantages of surface-based analysis is the ability to **visualize functional activation patterns** (from fMRI) on the cortical surface. This reveals activity hidden in deep sulci that would be difficult to see in traditional 3D volume renderings.\n","\n","Here we take a statistical map from a motor task fMRI study and project it from\n","volumetric space onto the cortical surface. This process (volume-to-surface mapping) samples the 3D statistical values onto each vertex of the 2D surface mesh.\n","\n","The result shows motor cortex activation spread across the surface, making it\n","easier to see the spatial extent along gyri and into sulci:"],"metadata":{"id":"Gd2HgC3JFYlX"}},{"cell_type":"code","source":["# Load example statistical map\n","motor_images = datasets.fetch_neurovault_motor_task()\n","stat_map = motor_images.images[0]\n","\n","# Project volume to surface\n","from nilearn import surface\n","\n","texture_left = surface.vol_to_surf(stat_map, fsaverage['pial_left'])\n","\n","view = plotting.view_surf(\n","    fsaverage['pial_left'],\n","    surf_map=texture_left,\n","    threshold=3.0,\n","    cmap='cold_hot',\n","    title='Motor Task Activation on Surface',\n","    black_bg=True\n",")\n","view"],"metadata":{"id":"cXlXIrbq8C7I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ufA1HHnn2w-"},"source":["# **VII: Final Exercise**\n","\n","**Objective:** Combine skull-stripping, segmentation, and registration to create a high-confidence White Matter (WM) mask in MNI standard space.\n","\n","### **Instructions:**\n","1. **Brain Extraction**: Use `bet` with the `-R` (robust) option on `T1.nii.gz`.\n","2. **Segmentation**: Use `fast` to segment the brain into different tissues.\n","3. **Thresholding**: Extract the White Matter (PVE segment 2) and threshold it at **0.9** using `fslmaths` to create a binary mask.\n","4. **Registration**: Apply the non-linear warp previously calculated during class (`T1toMNI_warp.nii.gz`) to move your **native WM mask** into **MNI standard space** using `applywarp`.\n","5. **Visualization**: Display the final mask over the standard template."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWLhBgawn2fA"},"outputs":[],"source":["# 1. Brain Extraction (Robust)\n","!bet T1.nii.gz T1_robust_brain.nii.gz -R"]},{"cell_type":"code","source":["# 2. Tissue Segmentation\n","!fast -b -B T1_robust_brain.nii.gz"],"metadata":{"id":"B0lCgLvifp8O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Create White Matter Mask (Segment 2)\n","# We use -thr 0.9 to keep only voxels with >90% probability of being WM\n","!fslmaths T1_robust_brain_pve_2.nii.gz -thr 0.9 -bin T1_WM_mask_native.nii.gz"],"metadata":{"id":"zB5phqWpfspF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Apply non-linear registration to standard space\n","!applywarp -i T1_WM_mask_native.nii.gz -r standard.nii.gz -w T1toMNI_warp.nii.gz -o T1_WM_mask_MNI.nii.gz"],"metadata":{"id":"-ZABQdDGfvH6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}